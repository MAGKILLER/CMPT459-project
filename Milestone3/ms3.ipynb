{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "import zipfile\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        bathrooms  bedrooms                       building_id  \\\n",
      "4             1.0         1  8579a0b0d54db803821a35a4a615e97a   \n",
      "6             1.0         2  b8e75fc949a6cd8225b455648a951712   \n",
      "9             1.0         2  cd759a988b8f23924b5a2058d5ab2b49   \n",
      "10            1.5         3  53a5b119ba8f7b61d4e010512e0dfc85   \n",
      "15            1.0         0  bfb9405149bfff42a92980b594c28234   \n",
      "...           ...       ...                               ...   \n",
      "124000        1.0         3  92bbbf38baadfde0576fc496bd41749c   \n",
      "124002        1.0         2  5565db9b7cba3603834c4aa6f2950960   \n",
      "124004        1.0         1  67997a128056ee1ed7d046bbb856e3c7   \n",
      "124008        1.0         2  3c0574a740154806c18bdf1fddd3d966   \n",
      "124009        1.0         3  d89f514c3ed0abaae52cba7017ac0701   \n",
      "\n",
      "                    created  \\\n",
      "4       2016-06-16 05:55:27   \n",
      "6       2016-06-01 05:44:33   \n",
      "9       2016-06-14 15:19:59   \n",
      "10      2016-06-24 07:54:24   \n",
      "15      2016-06-28 03:50:23   \n",
      "...                     ...   \n",
      "124000  2016-04-05 03:58:33   \n",
      "124002  2016-04-02 02:25:31   \n",
      "124004  2016-04-26 05:42:03   \n",
      "124008  2016-04-19 02:47:33   \n",
      "124009  2016-04-20 05:34:00   \n",
      "\n",
      "                                              description  \\\n",
      "4       Spacious 1 Bedroom 1 Bathroom in Williamsburg!...   \n",
      "6       BRAND NEW GUT RENOVATED TRUE 2 BEDROOMFind you...   \n",
      "9       **FLEX 2 BEDROOM WITH FULL PRESSURIZED WALL**L...   \n",
      "10      A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...   \n",
      "15      Over-sized Studio w abundant closets. Availabl...   \n",
      "...                                                   ...   \n",
      "124000  There is 700 square feet of recently renovated...   \n",
      "124002  2 bedroom apartment with updated kitchen, rece...   \n",
      "124004  No Brokers Fee * Never Lived 1 Bedroom 1 Bathr...   \n",
      "124008  Wonderful Bright Chelsea 2 Bedroom apartment o...   \n",
      "124009  ***PRIME MIDTOWN EAST OFF PARK AVE***TRUE 3 BE...   \n",
      "\n",
      "             display_address  \\\n",
      "4        145 Borinquen Place   \n",
      "6                  East 44th   \n",
      "9           East 56th Street   \n",
      "10       Metropolitan Avenue   \n",
      "15          East 34th Street   \n",
      "...                      ...   \n",
      "124000          W 171 Street   \n",
      "124002              Broadway   \n",
      "124004  210 Brighton 15th St   \n",
      "124008      West 21st Street   \n",
      "124009             E 54th St   \n",
      "\n",
      "                                                 features  latitude  \\\n",
      "4       [Dining Room, Pre-War, Laundry in Building, Di...   40.7108   \n",
      "6       [Doorman, Elevator, Laundry in Building, Dishw...   40.7513   \n",
      "9       [Doorman, Elevator, Laundry in Building, Laund...   40.7575   \n",
      "10                                                     []   40.7145   \n",
      "15      [Doorman, Elevator, Fitness Center, Laundry in...   40.7439   \n",
      "...                                                   ...       ...   \n",
      "124000            [Elevator, Dishwasher, Hardwood Floors]   40.8433   \n",
      "124002  [Common Outdoor Space, Cats Allowed, Dogs Allo...   40.8198   \n",
      "124004  [Dining Room, Elevator, Pre-War, Laundry in Bu...   40.5765   \n",
      "124008  [Pre-War, Laundry in Unit, Dishwasher, No Fee,...   40.7448   \n",
      "124009  [Dining Room, Elevator, Laundry in Building, D...   40.7594   \n",
      "\n",
      "        listing_id  longitude                        manager_id  \\\n",
      "4          7170325   -73.9539  a10db4590843d78c784171a107bdacb4   \n",
      "6          7092344   -73.9722  955db33477af4f40004820b4aed804a0   \n",
      "9          7158677   -73.9625  c8b10a317b766204f08e613cef4ce7a0   \n",
      "10         7211212   -73.9425  5ba989232d0489da1b5f2c45f6688adc   \n",
      "15         7225292   -73.9743  2c3b41f588fbb5234d8a1e885a436cfa   \n",
      "...            ...        ...                               ...   \n",
      "124000     6824800   -73.9396  a61e21da3ba18c7a3d54cfdcc247e1f8   \n",
      "124002     6813268   -73.9578  8f90e5e10e8a2d7cf997f016d89230eb   \n",
      "124004     6927093   -73.9554  a10db4590843d78c784171a107bdacb4   \n",
      "124008     6892816   -74.0017  c3cd45f4381ac371507090e9ffabea80   \n",
      "124009     6901023   -73.9712  e90f2ded843cdb2efd65ef47d9fc8029   \n",
      "\n",
      "                                                   photos  price  \\\n",
      "4       [https://photos.renthop.com/2/7170325_3bb5ac84...   2400   \n",
      "6       [https://photos.renthop.com/2/7092344_7663c19a...   3800   \n",
      "9       [https://photos.renthop.com/2/7158677_c897a134...   3495   \n",
      "10      [https://photos.renthop.com/2/7211212_1ed4542e...   3000   \n",
      "15      [https://photos.renthop.com/2/7225292_901f1984...   2795   \n",
      "...                                                   ...    ...   \n",
      "124000  [https://photos.renthop.com/2/6824800_0682be16...   2800   \n",
      "124002  [https://photos.renthop.com/2/6813268_1e6fcc32...   2395   \n",
      "124004  [https://photos.renthop.com/2/6927093_93a52104...   1850   \n",
      "124008  [https://photos.renthop.com/2/6892816_1a8d087a...   4195   \n",
      "124009  [https://photos.renthop.com/2/6901023_02052d90...   4280   \n",
      "\n",
      "                 street_address interest_level  \n",
      "4           145 Borinquen Place         medium  \n",
      "6                 230 East 44th            low  \n",
      "9          405 East 56th Street         medium  \n",
      "10      792 Metropolitan Avenue         medium  \n",
      "15         340 East 34th Street            low  \n",
      "...                         ...            ...  \n",
      "124000         620 W 171 Street            low  \n",
      "124002            3333 Broadway         medium  \n",
      "124004     210 Brighton 15th St         medium  \n",
      "124008     350 West 21st Street         medium  \n",
      "124009            123 E 54th St           high  \n",
      "\n",
      "[49352 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json (r'train.json')\n",
    "dt = pd.read_json (r'test.json')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "\n",
    "data = data.drop('building_id', axis=1)\n",
    "data = data.drop('created', axis=1)\n",
    "data = data.drop('description', axis=1)\n",
    "data = data.drop('display_address', axis=1)\n",
    "data = data.drop('listing_id', axis=1)\n",
    "data = data.drop('photos', axis=1)\n",
    "data = data.drop('street_address', axis=1)\n",
    "data = data.drop('features', axis=1)\n",
    "data = data.drop('manager_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    outdoor  no_fee  laundry  animal_allow  bathrooms  bedrooms  latitude  \\\n",
      "0         1       0        1             0        1.0         1   40.7185   \n",
      "1         0       0        0             1        1.0         2   40.7278   \n",
      "2         0       0        0             1        1.0         0   40.7260   \n",
      "3         0       0        0             1        1.0         2   40.7321   \n",
      "5         1       0        1             1        1.0         1   40.7054   \n",
      "7         1       1        1             1        2.0         2   40.7610   \n",
      "8         0       0        0             1        3.5         4   40.7358   \n",
      "11        0       1        1             0        1.0         0   40.7814   \n",
      "12        0       1        0             0        2.0         4   40.7216   \n",
      "13        0       0        0             1        1.0         1   40.7553   \n",
      "14        0       0        0             0        1.0         1   40.7623   \n",
      "17        1       1        1             0        1.0         1   40.7678   \n",
      "20        0       1        1             1        1.0         0   40.7823   \n",
      "21        0       0        0             1        1.5         1   40.6782   \n",
      "22        0       0        1             0        1.0         1   40.7749   \n",
      "24        0       1        1             0        1.0         2   40.7372   \n",
      "25        0       0        0             1        1.0         2   40.7675   \n",
      "26        1       1        1             0        1.0         2   40.7180   \n",
      "27        0       1        1             1        1.0         1   40.7943   \n",
      "28        0       0        0             0        1.0         2   40.8261   \n",
      "\n",
      "    listing_id  longitude  price  \n",
      "0      7142618   -73.9865   2950  \n",
      "1      7210040   -74.0000   2850  \n",
      "2      7174566   -74.0026   2295  \n",
      "3      7191391   -74.0028   2900  \n",
      "5      7171695   -74.0095   3254  \n",
      "7      7225206   -73.9983   4990  \n",
      "8      7200075   -73.9877  20000  \n",
      "11     7145074   -73.9507   2150  \n",
      "12     7193645   -73.9927   6500  \n",
      "13     7147703   -73.9953   3365  \n",
      "14     7182218   -73.9590   2500  \n",
      "17     7132136   -73.9915   3777  \n",
      "20     7130670   -73.9459   2400  \n",
      "21     7151855   -73.9750   2800  \n",
      "22     7158358   -73.9782   3150  \n",
      "24     7221001   -73.9981   5400  \n",
      "25     7100305   -73.9594   2250  \n",
      "26     7096581   -74.0112   4250  \n",
      "27     7177904   -73.9675   3000  \n",
      "28     7122823   -73.9387   1785  \n"
     ]
    }
   ],
   "source": [
    "test = dt\n",
    "\n",
    "test = test.drop('building_id', axis=1)\n",
    "test = test.drop('created', axis=1)\n",
    "test = test.drop('description', axis=1)\n",
    "test = test.drop('display_address', axis=1)\n",
    "test = test.drop('photos', axis=1)\n",
    "test = test.drop('street_address', axis=1)\n",
    "test = test.drop('manager_id', axis=1)\n",
    "test.insert(0,\"animal_allow\",0)\n",
    "test.insert(0,\"laundry\",0)\n",
    "test.insert(0,\"no_fee\",0)\n",
    "test.insert(0,\"outdoor\",0)\n",
    "test.features = test.features.astype(str)\n",
    "test.loc[test['features'].str.contains('Cats Allowed|Dogs Allowed'), 'animal_allow'] = 1\n",
    "test.loc[test['features'].str.contains('Laundry'), 'laundry'] = 1\n",
    "test.loc[test['features'].str.contains('No Fee'), 'no_fee'] = 1\n",
    "test.loc[test['features'].str.contains('Roof Deck|Balcony|Garden/Patio|Terrace|Outdoor Space'), 'outdoor'] = 1\n",
    "# data.loc[data['features'].str.contains('Doorman|Fitness|Swimming'), 'luxry'] = 1\n",
    "#data['support'][df.name.str.contains('ball')] = 'ball support'\n",
    "test = test.drop('features', axis=1)\n",
    "print(test.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        bathrooms  bedrooms  latitude  longitude  price\n",
      "37234         1.0         0   40.6985   -73.9940   2100\n",
      "63037         1.0         0   40.7602   -73.9689   2675\n",
      "37184         1.0         3   40.7864   -73.9515   3150\n",
      "14074         1.0         0   40.7249   -73.9795   1900\n",
      "119959        1.0         2   40.7874   -73.9738   2995\n",
      "...           ...       ...       ...        ...    ...\n",
      "109969        2.0         3   40.7567   -73.9980   5000\n",
      "81707         1.0         1   40.7878   -73.9799   2895\n",
      "13102         2.0         4   40.6404   -73.9546   3250\n",
      "30690         1.0         3   40.7657   -73.9572   3600\n",
      "82857         1.0         2   40.7568   -73.9982   3000\n",
      "\n",
      "[29611 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test , y_train, y_test = train_test_split(data.drop('interest_level', axis=1), data.interest_level, test_size=0.4, random_state=1)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        listing_id  high  medium  low\n",
      "0          7142618  0.00    0.30  0.7\n",
      "1          7210040  0.20    0.40  0.4\n",
      "2          7174566  0.00    0.80  0.2\n",
      "3          7191391  0.35    0.45  0.2\n",
      "5          7171695  0.00    0.30  0.7\n",
      "...            ...   ...     ...  ...\n",
      "124003     6928108  0.10    0.50  0.4\n",
      "124005     6906674  0.00    0.40  0.6\n",
      "124006     6897967  0.00    0.00  1.0\n",
      "124007     6842183  0.10    0.00  0.9\n",
      "124010     6889319  0.15    0.05  0.8\n",
      "\n",
      "[74659 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "## random forest default\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "y_proba = clf.predict_proba(test.drop('listing_id', axis=1))\n",
    "test_data = {'listing_id': test['listing_id'], 'high':y_proba[:,0], 'medium':y_proba[:,2], 'low':y_proba[:,1]}\n",
    "csvdat = pd.DataFrame(data = test_data)\n",
    "csvdat.to_csv(\"test_data de.csv\", index = False)\n",
    "print(csvdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "\n",
    "data = data.drop('building_id', axis=1)\n",
    "data = data.drop('created', axis=1)\n",
    "data = data.drop('description', axis=1)\n",
    "data = data.drop('display_address', axis=1)\n",
    "data = data.drop('listing_id', axis=1)\n",
    "data = data.drop('photos', axis=1)\n",
    "data = data.drop('street_address', axis=1)\n",
    "data = data.drop('manager_id', axis=1)\n",
    "data.insert(0,\"animal_allow\",0)\n",
    "data.insert(0,\"laundry\",0)\n",
    "data.insert(0,\"no_fee\",0)\n",
    "data.insert(0,\"outdoor\",0)\n",
    "data.features = data.features.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    outdoor  no_fee  laundry  animal_allow  bathrooms  bedrooms  latitude  \\\n",
      "4         0       0        1             1        1.0         1   40.7108   \n",
      "6         0       1        1             0        1.0         2   40.7513   \n",
      "9         0       0        1             0        1.0         2   40.7575   \n",
      "10        0       0        0             0        1.5         3   40.7145   \n",
      "15        0       0        1             0        1.0         0   40.7439   \n",
      "16        0       1        0             0        1.0         3   40.7348   \n",
      "18        0       1        1             0        2.0         3   40.7302   \n",
      "19        0       1        1             0        1.0         0   40.7769   \n",
      "23        0       0        0             0        0.0         1   40.7346   \n",
      "32        0       0        0             1        3.0         3   40.6990   \n",
      "33        0       0        1             1        1.0         0   40.7723   \n",
      "36        1       1        1             1        1.0         2   40.7530   \n",
      "38        1       1        1             0        1.0         0   40.7610   \n",
      "39        0       0        0             0        1.0         1   40.7277   \n",
      "42        0       1        1             1        2.0         2   40.7633   \n",
      "43        0       0        0             0        1.0         0   40.7073   \n",
      "44        0       0        0             0        1.0         2   40.7528   \n",
      "46        1       1        1             1        1.0         3   40.7360   \n",
      "49        0       0        0             0        1.0         1   40.7830   \n",
      "61        0       0        0             0        1.0         1   40.7621   \n",
      "\n",
      "    longitude  price interest_level  \n",
      "4    -73.9539   2400         medium  \n",
      "6    -73.9722   3800            low  \n",
      "9    -73.9625   3495         medium  \n",
      "10   -73.9425   3000         medium  \n",
      "15   -73.9743   2795            low  \n",
      "16   -73.9865   7200            low  \n",
      "18   -73.9826   6000            low  \n",
      "19   -73.9467   1945           high  \n",
      "23   -73.9811   2435            low  \n",
      "32   -73.9943   6850            low  \n",
      "33   -73.9510   2785            low  \n",
      "36   -73.9959   3100            low  \n",
      "38   -73.9990   2400         medium  \n",
      "39   -74.0000   2750            low  \n",
      "42   -73.9596   5465            low  \n",
      "43   -73.9665   3150            low  \n",
      "44   -73.9709   3750            low  \n",
      "46   -73.9860   4450           high  \n",
      "49   -73.9828   3200            low  \n",
      "61   -73.9486   2495            low  \n"
     ]
    }
   ],
   "source": [
    "data.loc[data['features'].str.contains('Cats Allowed|Dogs Allowed'), 'animal_allow'] = 1\n",
    "data.loc[data['features'].str.contains('Laundry'), 'laundry'] = 1\n",
    "data.loc[data['features'].str.contains('No Fee'), 'no_fee'] = 1\n",
    "data.loc[data['features'].str.contains('Roof Deck|Balcony|Garden/Patio|Terrace|Outdoor Space'), 'outdoor'] = 1\n",
    "# data.loc[data['features'].str.contains('Doorman|Fitness|Swimming'), 'luxry'] = 1\n",
    "#data['support'][df.name.str.contains('ball')] = 'ball support'\n",
    "data = data.drop('features', axis=1)\n",
    "print(data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        outdoor  no_fee  laundry  animal_allow  bathrooms  bedrooms  latitude  \\\n",
      "37234         0       0        0             1        1.0         0   40.6985   \n",
      "63037         0       1        1             1        1.0         0   40.7602   \n",
      "37184         0       0        0             1        1.0         3   40.7864   \n",
      "14074         0       0        0             1        1.0         0   40.7249   \n",
      "119959        0       1        1             0        1.0         2   40.7874   \n",
      "...         ...     ...      ...           ...        ...       ...       ...   \n",
      "109969        1       1        1             1        2.0         3   40.7567   \n",
      "81707         0       0        0             1        1.0         1   40.7878   \n",
      "13102         1       1        1             1        2.0         4   40.6404   \n",
      "30690         0       0        0             0        1.0         3   40.7657   \n",
      "82857         1       1        1             0        1.0         2   40.7568   \n",
      "\n",
      "        longitude  price  \n",
      "37234    -73.9940   2100  \n",
      "63037    -73.9689   2675  \n",
      "37184    -73.9515   3150  \n",
      "14074    -73.9795   1900  \n",
      "119959   -73.9738   2995  \n",
      "...           ...    ...  \n",
      "109969   -73.9980   5000  \n",
      "81707    -73.9799   2895  \n",
      "13102    -73.9546   3250  \n",
      "30690    -73.9572   3600  \n",
      "82857    -73.9982   3000  \n",
      "\n",
      "[29611 rows x 9 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7083734359961501"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## random forest default new features\n",
    "X_train, X_test , y_train, y_test = train_test_split(data.drop('interest_level', axis=1), data.interest_level, test_size=0.4, random_state=1)\n",
    "print(X_train)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7157967240420677"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=200)\n",
    "scores = cross_val_score(clf, data.drop('interest_level', axis=1), data.interest_level, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\users\\jackl\\anaconda3\\lib\\site-packages (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in c:\\users\\jackl\\anaconda3\\lib\\site-packages (from scikit-learn) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in c:\\users\\jackl\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\jackl\\anaconda3\\lib\\site-packages (from scikit-learn) (0.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackl\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7194845193710488"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = data.drop('interest_level', axis=1)\n",
    "y = data.interest_level\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "#    ('svr', make_pipeline(StandardScaler(), LinearSVC(random_state=42))),\n",
    "    ('svc',SVC(probability=True)),\n",
    "    ('rf_2', KNeighborsClassifier(n_neighbors=6)),\n",
    "    ('nb', GaussianNB()),\n",
    "    ('adb', AdaBoostClassifier(n_estimators=100, random_state=42)),\n",
    "    \n",
    "]\n",
    "clff = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42\n",
    ")\n",
    "clff.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        listing_id      high    medium       low\n",
      "0          7142618  0.042482  0.273814  0.683704\n",
      "1          7210040  0.097572  0.397847  0.504580\n",
      "2          7174566  0.087024  0.389507  0.523469\n",
      "3          7191391  0.218107  0.475581  0.306312\n",
      "5          7171695  0.011892  0.120436  0.867672\n",
      "...            ...       ...       ...       ...\n",
      "124003     6928108  0.142917  0.346891  0.510192\n",
      "124005     6906674  0.051797  0.296397  0.651806\n",
      "124006     6897967  0.016354  0.133532  0.850114\n",
      "124007     6842183  0.007180  0.067008  0.925812\n",
      "124010     6889319  0.031562  0.182622  0.785816\n",
      "\n",
      "[74659 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "y_proba = clff.predict_proba(test.drop('listing_id', axis=1))\n",
    "test_data = {'listing_id': test['listing_id'], 'high':y_proba[:,0], 'medium':y_proba[:,2], 'low':y_proba[:,1]}\n",
    "csvdat = pd.DataFrame(data = test_data)\n",
    "csvdat.to_csv(\"test_data2.csv\", index = False)\n",
    "print(csvdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4879576118718359\n",
      "0.719484519371049\n",
      "0.6841541495621957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_pre = clff.predict(X_test)\n",
    "print(f1_score(y_test, y_pre, average='macro'))\n",
    "print(f1_score(y_test, y_pre, average='micro'))\n",
    "print(f1_score(y_test, y_pre, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackl\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jackl\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jackl\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jackl\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jackl\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jackl\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\jackl\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8390338790727833"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop('interest_level', axis=1)\n",
    "y = data.interest_level\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "    ('svr', make_pipeline(StandardScaler(), LinearSVC(random_state=42))),\n",
    "    ('rf_2', KNeighborsClassifier(n_neighbors=5)),  \n",
    "    ('adb',  AdaBoostClassifier()), \n",
    "]\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7010050251256281"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop('interest_level', axis=1)\n",
    "y = data.interest_level\n",
    "\n",
    "layer_one_estimators = [\n",
    "                        ('rf_1', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "                        ('knn_1', KNeighborsClassifier(n_neighbors=5))             \n",
    "                       ]\n",
    "layer_two_estimators = [\n",
    "                        ('dt_2', DecisionTreeClassifier()),\n",
    "                        ('rf_2', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "                       ]\n",
    "layer_two = StackingClassifier(estimators=layer_two_estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# Create Final model by \n",
    "clf = StackingClassifier(estimators=layer_one_estimators, final_estimator=layer_two)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import numpy as np\n",
    " \n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    " \n",
    "# Utilities\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from copy import copy as make_copy\n",
    "X = data.drop('interest_level', axis=1)\n",
    "y = data.interest_level\n",
    "base_clf = [RandomForestClassifier(), LogisticRegression(), \n",
    "            AdaBoostClassifier(), #SVC(probability=True),\n",
    "            KNeighborsClassifier(n_neighbors=5)]\n",
    "stck_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Accuracy: 71.52%\n",
      "LogisticRegression Accuracy: 69.46%\n",
      "AdaBoostClassifier Accuracy: 71.56%\n",
      "KNeighborsClassifier Accuracy: 68.60%\n"
     ]
    }
   ],
   "source": [
    "SEED = 2018\n",
    "for clf in base_clf:\n",
    "    \n",
    "    # Set seed\n",
    "    if 'random_state' in clf.get_params().keys():\n",
    "        clf.set_params(random_state=SEED)\n",
    "    \n",
    "    # Fit model\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print('{} Accuracy: {:.2f}%'.format(clf.__class__.__name__, acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(\n",
    "    estimators=base_clf, final_estimator=LogisticRegression()\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #2 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-5fdb707ca4f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'final_estimator_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;31m# all_estimators contains all estimators, the one to be fitted and the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# 'drop' string.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_final_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[1;34m\" of (string, estimator) tuples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             )\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[1;31m# defined by MetaEstimatorMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: zip argument #2 must support iteration"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_test, y_pre, average='macro'))\n",
    "print(f1_score(y_test, y_pre, average='micro'))\n",
    "print(f1_score(y_test, y_pre, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
